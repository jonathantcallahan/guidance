{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathantcallahan/guidance/blob/main/book_processing_gpt_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFy5tIxFFQgw",
        "outputId": "4ab1d0d3-6011-4a0d-f0c5-b6447b3a48d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.33.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "%pip install chardet\n",
        "%pip install ftfy\n",
        "%pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "%pip install --no-deps xformers trl peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "id": "HJC-celAyjel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT7J6KmGcx1d"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import uuid\n",
        "import json\n",
        "from ftfy import fix_encoding\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq8SJJM_yVIh"
      },
      "outputs": [],
      "source": [
        "import chardet\n",
        "\n",
        "def detect_encoding(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        raw_data = file.read()\n",
        "    result = chardet.detect(raw_data)\n",
        "    encoding = result['encoding']\n",
        "    return encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vF1LcXlyVIi",
        "outputId": "c530fe56-0189-40ae-97bf-caace94dc3e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Books in list: 45\n"
          ]
        }
      ],
      "source": [
        "filenames = []\n",
        "\n",
        "for filename in os.listdir('books'):\n",
        "    filenames.append(filename)\n",
        "\n",
        "print(f'Books in list: {len(filenames)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmHX9WbfyVIi"
      },
      "outputs": [],
      "source": [
        "#generate quetsions to the \"answers\" extracted from the text\n",
        "def answer_gpt(answer):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are assisting in the generation of training data for fine-tuning. You will receive a chunk of text, and will respond with a short casually phrased question to which the chunk of text you received would be an expected answer. The person who generated the answer is Alan Watt's and often he will give a response that answers a question only indirectly. The question should not exactly contain the subject matter of the answer. The question you create should be one to which the answer would be a correct indirect or metaphorical answer.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Return a short casually phrased question to which this text would be an appropriate. The question should not reference the core subject matter of the answer in an overt way. : {answer}\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuM5t13myVIi"
      },
      "outputs": [],
      "source": [
        "#split chunks into sections that could reasonably be the answer to a question\n",
        "def chunk_gpt(text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a document processor used to create fine-tuning data. You will receive 5000 characters worth of a book, and extract portions of text that would be coherent as the answer to a theoretical, unspecified question. Each answer can be up to 200 words. The cohesive answers within the text may directly following each other and there may be space between them that needs to be removed. The response you provide should strictly be the series of cohesive thoughts identified within the content separated by line breaks. Minor grammatical may be made as needed. \"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Extract chunks of text from this page that would be coherent as responses to an unspecified question. :\\n\\n{text}\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9glYGYV5yVIj"
      },
      "outputs": [],
      "source": [
        "#loop through all of the processed \"answers\" and generate questions\n",
        "def process_questions(processed_answers, book_name):\n",
        "    for i in range(len(processed_answers)):\n",
        "\n",
        "        #limiting cycles for testing\n",
        "        if i > 2 and debugger == True:\n",
        "            continue\n",
        "\n",
        "        answer = processed_answers[i]\n",
        "        #remove blanks\n",
        "        if len(answer) < 30:\n",
        "            continue\n",
        "\n",
        "        question = answer_gpt(answer)\n",
        "\n",
        "        json_obj = {\n",
        "            \"book\" : book_name,\n",
        "            \"instruction\" : \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
        "            \"input\" : question,\n",
        "            \"output\" : answer\n",
        "        }\n",
        "\n",
        "        processed_json.append(json_obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8zLf8sEyVIj"
      },
      "outputs": [],
      "source": [
        "#loop through the chunks of a book\n",
        "def process_book_chunks(text_chunks, book_name):\n",
        "    print(f'Processing {len(text_chunks)} chunks for {book_name}')\n",
        "    for i in range(len(text_chunks)):\n",
        "        chunk = fix_encoding(text_chunks[i])\n",
        "\n",
        "        #skip the first and last pages which are usually credits and other misellaneous content\n",
        "        if i > len(text_chunks)-8 or i < 8:\n",
        "            continue\n",
        "\n",
        "        #limiting requests for testing purposes\n",
        "        if i > 9 and debugger == True:\n",
        "            continue\n",
        "\n",
        "        processed_answers = chunk_gpt(chunk)\n",
        "        process_questions(processed_answers, book_name)\n",
        "    print(f'Completed processing {book_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0JUUYVMyVIj"
      },
      "outputs": [],
      "source": [
        "#process books into chunks of characters\n",
        "def process_books():\n",
        "    chunk_size = 5000\n",
        "    for i in range(len(filenames)):\n",
        "\n",
        "        #limiting cycles for testing\n",
        "        if i > 0 and debugger == True:\n",
        "            continue\n",
        "\n",
        "        encoding = detect_encoding(f'books/{filenames[i]}')\n",
        "        with open(f'books/{filenames[i]}', 'r', encoding=encoding, errors='replace') as file:\n",
        "            content = file.read().replace('\\n','')\n",
        "            text_chunks = [content[i:i + chunk_size] for i in range(0, len(content), chunk_size)]\n",
        "\n",
        "            process_book_chunks(text_chunks, filenames[i])\n",
        "\n",
        "    print(fix_encoding(json.dumps(processed_json, indent=4, ensure_ascii=False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBklbArIyVIj"
      },
      "outputs": [],
      "source": [
        "processed_json = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtzP7MlTyVIj",
        "outputId": "98b0b80f-da6d-47b5-ab12-da09240425a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 304 chunks for Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\n",
            "Completed processing Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\n",
            "[\n",
            "    {\n",
            "        \"book\": \"Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\",\n",
            "        \"instruction\": \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
            "        \"input\": \"What's something unique you've noticed about certain symbolic representations?\",\n",
            "        \"output\": \"Apart from the six divisions, another feature, which distinguishes it from the usual mandala is its centre. Almost all the examples you showed, except some produced by pathological cases, had at the centre some kind of \\u201choly of holies\\u201d \\u2014 a temple, an egg, or a golden ball. The Buddhist Wheel, however, has a cock, a snake, and a hog, the symbols of lust (raga), ill-will (dosa), and stupidity (moha). I have never come across any instance of its being used for magical purposes.\"\n",
            "    },\n",
            "    {\n",
            "        \"book\": \"Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\",\n",
            "        \"instruction\": \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
            "        \"input\": \"Why do you think some traditions depict their symbols differently?\",\n",
            "        \"output\": \"It is interesting to note that in the many Tibetan wheels of this kind, the figure of the Buddha appears in each of the six divisions to show that the phenomenal world is actually a manifestation of the Buddha nature. In this particular wheel, the Buddha only appears in four sections.\"\n",
            "    },\n",
            "    {\n",
            "        \"book\": \"Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\",\n",
            "        \"instruction\": \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
            "        \"input\": \"How do people express deep thoughts in surprising ways?\",\n",
            "        \"output\": \"\\u201cYou can imagine how utterly perplexed I am by this sort of thing: \\u2018One day Goso entered the hall and seated himself on the chair. He looked one way over one shoulder, and then the other. Finally he held out his staff high in his hand and said, 'Only one foot long!'\\\"\"\n",
            "    },\n",
            "    {\n",
            "        \"book\": \"Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\",\n",
            "        \"instruction\": \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
            "        \"input\": \"Have you ever met someone who left a lifelong impression on you?\",\n",
            "        \"output\": \"In the summer of 1937, he again attended the World Congress of Faiths, this time held in Oxford, and found conversations with many illustrious scholars informative and stimulating. He met Jiddu Krishnamurti, from Benares, India, adopted son of Annie Besant. She was a leader of the Theosophical Society who promoted Krishnamurti as the vehicle of the coming World Teacher. Krishnamurti disavowed such a notion, along with allegiance to any particular religion, but became a speaker and philosophical writer that Alan greatly admired all his life.\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "debugger = True\n",
        "process_books()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeO9kjhJyVIj"
      },
      "outputs": [],
      "source": [
        "with open('chunks_3_through_189','r') as f1:\n",
        "    book_one = json.load(f1)\n",
        "\n",
        "with open('more_chunks', 'r') as f2:\n",
        "    book_two = json.load(f2)\n",
        "\n",
        "combined_data = book_one + book_two\n",
        "\n",
        "with open('first_batch_total', 'w') as f_combined:\n",
        "    json.dump(combined_data, f_combined, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoLIiC6kyVIj",
        "outputId": "9ecc6b2a-d9e9-4d6e-9794-0ffa43f3b0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"book\": \"Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\",\n",
            "        \"instruction\": \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
            "        \"input\": \"What's something unique you've noticed about certain symbolic representations?\",\n",
            "        \"output\": \"Apart from the six divisions, another feature, which distinguishes it from the usual mandala is its centre. Almost all the examples you showed, except some produced by pathological cases, had at the centre some kind of “holy of holies” — a temple, an egg, or a golden ball. The Buddhist Wheel, however, has a cock, a snake, and a hog, the symbols of lust (raga), ill-will (dosa), and stupidity (moha). I have never come across any instance of its being used for magical purposes.\"\n",
            "    },\n",
            "    {\n",
            "        \"book\": \"Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\",\n",
            "        \"instruction\": \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
            "        \"input\": \"Why do you think some traditions depict their symbols differently?\",\n",
            "        \"output\": \"It is interesting to note that in the many Tibetan wheels of this kind, the figure of the Buddha appears in each of the six divisions to show that the phenomenal world is actually a manifestation of the Buddha nature. In this particular wheel, the Buddha only appears in four sections.\"\n",
            "    },\n",
            "    {\n",
            "        \"book\": \"Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\",\n",
            "        \"instruction\": \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
            "        \"input\": \"How do people express deep thoughts in surprising ways?\",\n",
            "        \"output\": \"“You can imagine how utterly perplexed I am by this sort of thing: ‘One day Goso entered the hall and seated himself on the chair. He looked one way over one shoulder, and then the other. Finally he held out his staff high in his hand and said, 'Only one foot long!'\\\"\"\n",
            "    },\n",
            "    {\n",
            "        \"book\": \"Alan W. Watts_ Joan Watts_ Anne Watts - -New World Library (2018)_djvu.txt\",\n",
            "        \"instruction\": \"You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\",\n",
            "        \"input\": \"Have you ever met someone who left a lifelong impression on you?\",\n",
            "        \"output\": \"In the summer of 1937, he again attended the World Congress of Faiths, this time held in Oxford, and found conversations with many illustrious scholars informative and stimulating. He met Jiddu Krishnamurti, from Benares, India, adopted son of Annie Besant. She was a leader of the Theosophical Society who promoted Krishnamurti as the vehicle of the coming World Teacher. Krishnamurti disavowed such a notion, along with allegiance to any particular religion, but became a speaker and philosophical writer that Alan greatly admired all his life.\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(fix_encoding(json.dumps(processed_json, indent=4, ensure_ascii=False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmeemUtpyVIk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}