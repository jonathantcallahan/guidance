{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathantcallahan/guidance/blob/main/colab_book_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers trl peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmUBVEnvCDJv"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85afa77-1bfb-482e-bc11-881eef3745d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt_batch = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction: You are a document processor used to create fine-tuning data. You will receive 5000 characters worth of a book, and extract portions of text that would be coherent as the answer to a theoretical, unspecified question. Each answer can be up to 200 words. The cohesive answers within the text may directly following each other and there may be space between them that needs to be removed. The response you provide should strictly be the series of cohesive thoughts identified within the content separated by line breaks. Minor grammatical may be made as needed.\n",
        "\n",
        "### Input:\n",
        "Extract chunks of text from this page that would be coherent as responses to an unspecified question. :\\n\\n{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "alpaca_prompt_question = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction: You are English author and intellectual Alan Watts. Please answer the following question using your standard speech patterns but do not over-embellish.\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "id": "0U25Q-F_JOzr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_text = \"\"\"reference—as that I am human, male, Caucasian, adult,\n",
        "American, professor, and so forth. When the frames are\n",
        "larger than human—mammal, organic, existent—they begin\n",
        "to lose meaning. The same is true when they become\n",
        "smaller than the frame designated by my proper name—\n",
        "tissue, cells, molecules, atoms, electrons, et cetera. Yet,\n",
        "large or small, every one of these identifying terms is the\n",
        "name of a frame, and there seems to be no way of saying or\n",
        "thinking what I am except in terms of frames. This gives me\n",
        "a peculiarly empty feeling, so that I begin to feel like the\n",
        "Irishman’s definition of a net—”a lot of holes tied together\n",
        "with string.”\n",
        "\n",
        "The curious human mind has always wanted to know\n",
        "“what” is inside the frames, and for an answer it gets only\n",
        "the names of still smaller frames. In modern philosophy it is\n",
        "no longer considered proper to ask what anything is, unless\n",
        "you are simply speaking about its class or frame, or unless\n",
        "you are asking what it does—unless, that is, you are asking\n",
        "for an “operational definition.” But even operational\n",
        "definitions—running, jumping, hopping, wobbling—are the\n",
        "names of frames, of classes of movement and behavior. The\n",
        "problem is that thought and language have no terms except\n",
        "frame-terms, and there is really no way of even phrasing\n",
        "one’s question so as to speak of what is not a frame. To ask,\n",
        "“What?” is to ask, “What frame?” for there are no means of\n",
        "saying what anything is save by denoting its class, by\n",
        "describing its “difference” from other things, which is\n",
        "simply to designate its boundaries, its frame.\n",
        "\n",
        "In many schools of philosophy, stray thoughts that\n",
        "quarrel with this conclusion are simply outlawed as\n",
        "meaningless nonsense. The philosophers must at all costs\n",
        "convince themselves that life is composed of frames and\n",
        "frames alone, overlooking the fact that frames are “airy\n",
        "\n",
        "\n",
        "nothings” in their enthusiasm for the fact that, hollow as\n",
        "they may be, they are at least definite. The philosophers\n",
        "will also contend that such knowledge amounts to far more\n",
        "than a vain effort to catch the wind in nets. After all it is the\n",
        "very nature of scientific knowledge; and look what science\n",
        "has achieved in the realm of concrete experience—at the\n",
        "innumerable ways in which it has made it easier and more\n",
        "pleasant to survive in this world as human beings.\n",
        "\n",
        "One may wonder how close Western philosophy is\n",
        "coming to a realization that the “real material world”\n",
        "composed entirely of these frames is a vast net of\n",
        "abstractions. This will, perhaps, be difficult to see so long\n",
        "as we pretend to be really satisfied with the technological\n",
        "miracles of science—so long as the prospects of longer and\n",
        "more pleasant lives can distract our attention and keep it\n",
        "well within the limits of the frame called birth-and-death.\n",
        "But people have never been willing to remain closed in\n",
        "boxes for very long, and the wiser orthodoxies have used\n",
        "them as wise parents provide playpens for their babies. On\n",
        "the one hand, the pen is a safe place where baby can stay\n",
        "out of trouble. On the other, there is a proper parental\n",
        "pride in seeing the baby grow strong enough to climb over\n",
        "the fence. The trouble with so many Western orthodoxies is\n",
        "that they have been living inside the pen with the baby.\n",
        "They have never allowed those who went outside to return\n",
        "unless they promise never to go out again. It is for this\n",
        "reason that the great Western orthodoxies, religious and\n",
        "scientific, have been strictly exoteric and profane. They\n",
        "have never had the secret smile of the parent who lays\n",
        "down rules in the hope that they will eventually be\n",
        "disobeyed. But that is the smile on the face of the sphinx,\n",
        "and on the faces of meditating buddhas. \"\"\""
      ],
      "metadata": {
        "id": "rp5R_QwbxMgj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt_batch.format(\n",
        "        book_text, # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "kR3gIAX-SM2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e51d382-84b7-4f14-b117-4d5a5ff34857"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction: You are a document processor used to create fine-tuning data. You will receive 5000 characters worth of a book, and extract portions of text that would be coherent as the answer to a theoretical, unspecified question. Each answer can be up to 200 words. The cohesive answers within the text may directly following each other and there may be space between them that needs to be removed. The response you provide should strictly be the series of cohesive thoughts identified within the content separated by line breaks. Minor grammatical may be made as needed. \\n\\n### Input:\\nExtract chunks of text from this page that would be coherent as responses to an unspecified question. :\\n\\nreference—as that I am human, male, Caucasian, adult, \\nAmerican, professor, and so forth. When the frames are \\nlarger than human—mammal, organic, existent—they begin \\nto lose meaning. The same is true when they become \\nsmaller than the frame designated by my proper name— \\ntissue, cells, molecules, atoms, electrons, et cetera. Yet, \\nlarge or small, every one of these identifying terms is the \\nname of a frame, and there seems to be no way of saying or \\nthinking what I am except in terms of frames. This gives me \\na peculiarly empty feeling, so that I begin to feel like the \\nIrishman’s definition of a net—”a lot of holes tied together \\nwith string.” \\n\\nThe curious human mind has always wanted to know \\n“what” is inside the frames, and for an answer it gets only \\nthe names of still smaller frames. In modern philosophy it is \\nno longer considered proper to ask what anything is, unless \\nyou are simply speaking about its class or frame, or unless \\nyou are asking what it does—unless, that is, you are asking \\nfor an “operational definition.” But even operational \\ndefinitions—running, jumping, hopping, wobbling—are the \\nnames of frames, of classes of movement and behavior. The \\nproblem is that thought and language have no terms except \\nframe-terms, and there is really no way of even phrasing \\none’s question so as to speak of what is not a frame. To ask, \\n“What?” is to ask, “What frame?” for there are no means of \\nsaying what anything is save by denoting its class, by \\ndescribing its “difference” from other things, which is \\nsimply to designate its boundaries, its frame. \\n\\nIn many schools of philosophy, stray thoughts that \\nquarrel with this conclusion are simply outlawed as \\nmeaningless nonsense. The philosophers must at all costs \\nconvince themselves that life is composed of frames and \\nframes alone, overlooking the fact that frames are “airy \\n\\n\\nnothings” in their enthusiasm for the fact that, hollow as \\nthey may be, they are at least definite. The philosophers \\nwill also contend that such knowledge amounts to far more \\nthan a vain effort to catch the wind in nets. After all it is the \\nvery nature of scientific knowledge; and look what science \\nhas achieved in the realm of concrete experience—at the \\ninnumerable ways in which it has made it easier and more \\npleasant to survive in this world as human beings. \\n\\nOne may wonder how close Western philosophy is \\ncoming to a realization that the “real material world” \\ncomposed entirely of these frames is a vast net of \\nabstractions. This will, perhaps, be difficult to see so long \\nas we pretend to be really satisfied with the technological \\nmiracles of science—so long as the prospects of longer and \\nmore pleasant lives can distract our attention and keep it \\nwell within the limits of the frame called birth-and-death. \\nBut people have never been willing to remain closed in \\nboxes for very long, and the wiser orthodoxies have used \\nthem as wise parents provide playpens for their babies. On \\nthe one hand, the pen is a safe place where baby can stay \\nout of trouble. On the other, there is a proper parental \\npride in seeing the baby grow strong enough to climb over \\nthe fence. The trouble with so many Western orthodoxies is \\nthat they have been living inside the pen with the baby. \\nThey have never allowed those who went outside to return \\nunless they promise never to go out again. It is for this \\nreason that the great Western orthodoxies, religious and \\nscientific, have been strictly exoteric and profane. They \\nhave never had the secret smile of the parent who lays \\ndown rules in the hope that they will eventually be \\ndisobeyed. But that is the smile on the face of the sphinx, \\nand on the faces of meditating buddhas. \\n\\n### Response:\\nThe curious human mind has always wanted to know \\n“what” is inside the frames, and for an answer it gets only \\nthe names of still smaller frames. In modern philosophy it is \\nno longer considered proper to ask what anything is, unless \\nyou are simply speaking about its class or frame, or unless \\n']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HptruhewxcT-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}