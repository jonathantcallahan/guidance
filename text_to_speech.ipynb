{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a10dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install elevenlabs\n",
    "!python -m pip install openai\n",
    "!python -m pip install numpy\n",
    "!python -m pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!python -m pip install moviepy\n",
    "!python -m pip install imageio==2.4.1\n",
    "!python -m pip install -r requirements.txt\n",
    "!python -m pip install cmake==3.25.2\n",
    "!python -m pip install boost==0.1\n",
    "!python -m pip install dlib-bin\n",
    "!python -m pip install basicsr==1.4.2\n",
    "!python -m pip install facexlib==0.2.5\n",
    "!python -m pip install kornia==0.6.10\n",
    "!python -m pip install face-alignment==1.3.4 yacs==0.1.8\n",
    "\n",
    "### install gpfgan for enhancer\n",
    "!python -m pip install git+https://github.com/TencentARC/GFPGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e664de0-f0e6-44e6-8c57-8e41b3b406eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import elevenlabs\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import uuid\n",
    "from dotenv import main\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from moviepy.video.fx.resize import resize\n",
    "from moviepy.editor import VideoFileClip\n",
    "from openai import OpenAI\n",
    "\n",
    "####\n",
    "import glob\n",
    "import numpy\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16be44c3-080f-4678-aa7a-d51776e12ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.load_dotenv()\n",
    "openai_api_key = os.getenv('openai_api_key')\n",
    "elevenlabs_api_key = os.getenv(\"elevenlabs_api_key\")\n",
    "\n",
    "#connect to elevenlabs, define the model \n",
    "elevenlabs.set_api_key(elevenlabs_api_key)\n",
    "voice_id = \"vDxT1hhO5CjgzUI7e2vF\"\n",
    "\n",
    "#connect to specific assistant and open new thread\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "assistant_id = \"asst_nv9sFR2LXHefrpwws4EUT6xU\"\n",
    "my_assistant = client.beta.assistants.retrieve(assistant_id)\n",
    "new_thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7246a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_generation(audio_path, audio_id):\n",
    "    \n",
    "    !python ./SadTalker/inference.py \\\n",
    "      --driven_audio test.wav \\\n",
    "      --source_image ./SadTalker/example_img.jpg \\\n",
    "      --result_dir ./results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41f74ad9-ce08-4ad3-af1c-8b2c0c4c23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_question(question_text):\n",
    "  message_request = client.beta.threads.messages.create(\n",
    "      thread_id = new_thread.id,\n",
    "      role = \"user\",\n",
    "      content = \"In 30 words or less (important). \" + question_text\n",
    "  )\n",
    "\n",
    "  run = client.beta.threads.runs.create(\n",
    "    thread_id = message_request.thread_id,\n",
    "    assistant_id = my_assistant.id\n",
    "  )\n",
    "\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id = message_request.thread_id,\n",
    "    run_id = run.id\n",
    "  )\n",
    "\n",
    "  def wait_for_completed():\n",
    "      print('thread message sent')\n",
    "      while True:\n",
    "          response = client.beta.threads.runs.retrieve(thread_id = new_thread.id, run_id = run.id)\n",
    "          if response.status == \"completed\":\n",
    "              print('thread response received')\n",
    "              return response\n",
    "          time.sleep(1)\n",
    "\n",
    "  run_return = wait_for_completed()\n",
    "\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id = message_request.thread_id\n",
    "  )\n",
    "\n",
    "  audio = elevenlabs.generate(\n",
    "      text = messages.data[0].content[0].text.value,\n",
    "          voice = voice_id\n",
    "  )\n",
    "\n",
    "  audio_id = uuid.uuid4()\n",
    "  elevenlabs.save(audio, \"test.wav\")\n",
    "  video_generation(\"test.wav\", audio_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b8810ec-7cc5-435d-a058-e9935fc9c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread message sent\n"
     ]
    }
   ],
   "source": [
    "new_question(\"What is the best morning routine?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bf926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
