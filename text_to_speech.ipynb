{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a10dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/kenwaytis/faster-SadTalker-API/blob/main/main.py\n",
    "\n",
    "!python -m pip install elevenlabs\n",
    "!python -m pip install openai\n",
    "!python -m pip install numpy\n",
    "!python -m pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!python -m pip install moviepy\n",
    "!python -m pip install imageio==2.4.1\n",
    "!python -m pip install -r requirements.txt\n",
    "!python -m pip install cmake==3.25.2\n",
    "!python -m pip install boost==0.1\n",
    "!python -m pip install dlib-bin\n",
    "!python -m pip install basicsr==1.4.2\n",
    "!python -m pip install facexlib==0.2.5\n",
    "!python -m pip install kornia==0.6.10\n",
    "!python -m pip install face-alignment==1.3.4 yacs==0.1.8\n",
    "\n",
    "### install gpfgan for enhancer\n",
    "!python -m pip install git+https://github.com/TencentARC/GFPGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e664de0-f0e6-44e6-8c57-8e41b3b406eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import elevenlabs\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import uuid\n",
    "from dotenv import main\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from moviepy.video.fx.resize import resize\n",
    "from moviepy.editor import VideoFileClip\n",
    "from openai import OpenAI\n",
    "\n",
    "####\n",
    "import glob\n",
    "import numpy\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16be44c3-080f-4678-aa7a-d51776e12ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.load_dotenv()\n",
    "openai_api_key = os.getenv('openai_api_key')\n",
    "elevenlabs_api_key = os.getenv(\"elevenlabs_api_key\")\n",
    "\n",
    "#connect to elevenlabs, define the model \n",
    "elevenlabs.set_api_key(elevenlabs_api_key)\n",
    "voice_id = \"vDxT1hhO5CjgzUI7e2vF\"\n",
    "\n",
    "#connect to specific assistant and open new thread\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "assistant_id = \"asst_nv9sFR2LXHefrpwws4EUT6xU\"\n",
    "my_assistant = client.beta.assistants.retrieve(assistant_id)\n",
    "new_thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7246a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_generation(audio_path, audio_id):\n",
    "    \n",
    "    !python ./SadTalker/inference.py \\\n",
    "      --driven_audio test.wav \\\n",
    "      --source_image ./SadTalker/example_img.jpg \\\n",
    "      --result_dir ./results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41f74ad9-ce08-4ad3-af1c-8b2c0c4c23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_question(question_text):\n",
    "  message_request = client.beta.threads.messages.create(\n",
    "      thread_id = new_thread.id,\n",
    "      role = \"user\",\n",
    "      content = \"In 30 words or less (important). \" + question_text\n",
    "  )\n",
    "\n",
    "  run = client.beta.threads.runs.create(\n",
    "    thread_id = message_request.thread_id,\n",
    "    assistant_id = my_assistant.id\n",
    "  )\n",
    "\n",
    "  run = client.beta.threads.runs.retrieve(\n",
    "    thread_id = message_request.thread_id,\n",
    "    run_id = run.id\n",
    "  )\n",
    "\n",
    "  def wait_for_completed():\n",
    "      print('thread message sent')\n",
    "      while True:\n",
    "          response = client.beta.threads.runs.retrieve(thread_id = new_thread.id, run_id = run.id)\n",
    "          if response.status == \"completed\":\n",
    "              print('thread response received')\n",
    "              return response\n",
    "          time.sleep(1)\n",
    "\n",
    "  run_return = wait_for_completed()\n",
    "\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id = message_request.thread_id\n",
    "  )\n",
    "\n",
    "  audio = elevenlabs.generate(\n",
    "      text = messages.data[0].content[0].text.value,\n",
    "          voice = voice_id\n",
    "  )\n",
    "\n",
    "  audio_id = uuid.uuid4()\n",
    "  elevenlabs.save(audio, \"test.wav\")\n",
    "  video_generation(\"test.wav\", audio_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b8810ec-7cc5-435d-a058-e9935fc9c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread message sent\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnew_question\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the best morning routine?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m, in \u001b[0;36mnew_question\u001b[1;34m(question_text)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m     25\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m run_return \u001b[38;5;241m=\u001b[39m \u001b[43mwait_for_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m messages \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mlist(\n\u001b[0;32m     30\u001b[0m   thread_id \u001b[38;5;241m=\u001b[39m message_request\u001b[38;5;241m.\u001b[39mthread_id\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m audio \u001b[38;5;241m=\u001b[39m elevenlabs\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     34\u001b[0m     text \u001b[38;5;241m=\u001b[39m messages\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m     35\u001b[0m         voice \u001b[38;5;241m=\u001b[39m voice_id\n\u001b[0;32m     36\u001b[0m )\n",
      "Cell \u001b[1;32mIn[24], line 25\u001b[0m, in \u001b[0;36mnew_question.<locals>.wait_for_completed\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthread response received\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_question(\"What is the best morning routine?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bf926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
